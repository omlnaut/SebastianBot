{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c81760",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/workspaces/SebastianBot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50eb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloud.dependencies.clients import resolve_reddit_client\n",
    "\n",
    "\n",
    "client = resolve_reddit_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3789d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RedditPost(subreddit=Subreddit(display_name='Python'), created_at=datetime.datetime(2025, 12, 22, 21, 35, 24, tzinfo=datetime.timezone.utc), title='Why does my price always gets smaller?', flair='Discussion', destination_url='https://www.reddit.com/r/Python/comments/1ptboo4/why_does_my_price_always_gets_smaller/', text='    import math\\n    import random\\n    import time\\n    \\n    \\n    # Start price\\n    Price = 1\\n    \\n    \\n    # 50% chance for upward or downward movement\\n    if random.random() < 0.5: \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\n    \\xa0 \\xa0 marketdirection = \"UP\"\\n    else:\\n    \\xa0 \\xa0 marketdirection = \"DOWN\"\\n    print(\"\\\\n\" * 10)\\n    print(\"market direction: \", marketdirection)\\n    # price grows\\n    if marketdirection == \"UP\": \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\n    \\xa0 \\xa0 x = 1 + (-math.log(1 - random.random())) * 0.1\\n    \\xa0 \\xa0 print(\"X = \", x) \\n    \\n    \\n    # price falls\\n    else: \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\n    \\xa0 \\xa0 x = -1 + (-math.log(1 - random.random())) * 0.1\\n    \\xa0 \\xa0 if x < 0:\\n    \\xa0 \\xa0 \\xa0 \\xa0 x *= -1\\n    \\xa0 \\xa0 print(\"X = \", x)\\n    \\n    \\n    # new price\\n    new_price = Price * x\\n    \\n    \\n    print(\"\\\\n\" * 1)\\n    print(\"new price: \", new_price)\\n    print(\"\\\\n\" * 1)\\n    \\n    \\n    # Endless loop\\n    while True: \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\n    \\xa0 \\xa0 response = input(\"press Enter to generate the next price \")\\n    \\xa0 \\xa0 if response == \"\":\\n    \\n    \\n    # \\xa0Update price \\xa0 \\xa0 \\xa0\\n    \\xa0 \\xa0 \\xa0 \\xa0 Price = new_price\\n    \\n    \\n    # Higher probability for same market direction\\n    \\xa0 \\xa0 \\xa0 \\xa0 if marketdirection == \"UP\":\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if random.random() < 0.65:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 marketdirection = \"UP\"\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 else:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 marketdirection = \"DOWN\"\\n    \\xa0 \\xa0 \\xa0 \\xa0 else:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if random.random() < 0.65:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 marketdirection = \"DOWN\"\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 else:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 marketdirection = \"UP\"\\n    \\xa0 \\xa0 \\xa0 \\xa0 print(\"\\\\n\" * 10)\\n    \\xa0 \\xa0 \\xa0 \\xa0 print(\"Marktrichtung: \", marketdirection)\\n    \\n    \\n    \\xa0 \\xa0 \\xa0 \\xa0 # price grows\\n    \\xa0 \\xa0 \\xa0 \\xa0 if marketdirection == \"UP\":\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 x = 1 + (-math.log(1 - random.random())) * 0.1\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 print(\"X = \", x)\\n    \\n    \\n    \\xa0 \\xa0 \\xa0 \\xa0 # price falls\\n    \\xa0 \\xa0 \\xa0 \\xa0 else:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 x = -1 + (-math.log(1 - random.random())) * 0.1\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 if x < 0:\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 x *= -1\\n    \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 print(\"X = \", x)\\n    \\n    \\n    \\xa0 \\xa0 \\xa0 \\xa0 # Update price\\n    \\xa0 \\xa0 \\xa0 \\xa0 print(\"\\\\n\" * 1)\\n    \\xa0 \\xa0 \\xa0 \\xa0 print(\"old price: \", Price)\\n    \\xa0 \\xa0 \\xa0 \\xa0 new_price = Price * x\\n    \\n    \\n    \\xa0 \\xa0 \\xa0 \\xa0 print(\"new price: \", new_price)\\n    \\xa0 \\xa0 \\xa0 \\xa0 print(\"\\\\n\" * 1)', comments=[RedditComment(text='+1+-x = a number between 0 and 1\\n\\n-1+-x = a number less than -1', created_at=datetime.datetime(2025, 12, 22, 21, 42, 54, tzinfo=datetime.timezone.utc)), RedditComment(text=\"This is a low effort post, so I'm giving you an answer, but also spending low effort.  \\nHere you go:  \\n[https://chatgpt.com/share/6949baf9-0228-8004-9150-b42592f186a8](https://chatgpt.com/share/6949baf9-0228-8004-9150-b42592f186a8)\", created_at=datetime.datetime(2025, 12, 22, 21, 42, 18, tzinfo=datetime.timezone.utc)), RedditComment(text=\"From my understanding x\\\\*= -1 is wrong but when I remove it it'll give me negative prices. How can I fix that?\", created_at=datetime.datetime(2025, 12, 22, 21, 50, 31, tzinfo=datetime.timezone.utc)), RedditComment(text='Try another random seed, perhaps.\\xa0', created_at=datetime.datetime(2025, 12, 22, 21, 44, 37, tzinfo=datetime.timezone.utc)), RedditComment(text=\"Why wouldn't you ask an AI instead of bothering a forum with this trivial question?\", created_at=datetime.datetime(2025, 12, 22, 21, 49, 42, tzinfo=datetime.timezone.utc)), RedditComment(text='I tried it like 10 times but still always end but at way below 1', created_at=datetime.datetime(2025, 12, 22, 21, 48, 59, tzinfo=datetime.timezone.utc)), RedditComment(text='The others are correct\\xa0', created_at=datetime.datetime(2025, 12, 22, 21, 49, 59, tzinfo=datetime.timezone.utc))]),\n",
       " RedditPost(subreddit=Subreddit(display_name='Python'), created_at=datetime.datetime(2025, 12, 22, 20, 28, 3, tzinfo=datetime.timezone.utc), title='What’s the slowest Python script you’re dealing with right now?', flair='Discussion', destination_url='https://www.reddit.com/r/Python/comments/1pta1k7/whats_the_slowest_python_script_youre_dealing/', text='Examples from recent clients:\\n\\n•  One guy’s reporting script went from 38s to 0.41s (93x)\\n\\n•  Another’s e-commerce ETL from 65s to 0.58s (112x)\\n\\n•  A daily analytics job from 51s to 0.44s (116x)\\n\\nAll with identical output — no cheating or cutting corners.\\n\\nSo I’m curious — what’s the slowest thing you’re running right now?\\n\\nHow many seconds/minutes does it take, and what does it do (roughly)?\\n\\nDrop it in the comments or DM me. I’ll give you a quick gut check on what speedup is usually possible — free', comments=[RedditComment(text='What are common causes?\\xa0', created_at=datetime.datetime(2025, 12, 22, 20, 31, 33, tzinfo=datetime.timezone.utc)), RedditComment(text='Slop', created_at=datetime.datetime(2025, 12, 22, 20, 40, 3, tzinfo=datetime.timezone.utc)), RedditComment(text='I inherited an application many, many years back that I was never quite able to nail down the big-O notation for due to its insane complexity. I *think* it was O(n log n). The home page would load every data point (yes everything). And for each data point it would query the entire database to see if the user had access to a single thing, but it went 7-13 layers deep depending on the type of object. Most of this was recursively checking for user access (again and again and again. The home page took 90-150 seconds to load depending on backend load (a fair amount going on). The database had something like 700 data points in it. I wrapped it in a a profiler and counted around 70-80k function calls just to look at a page for a single object.\\n\\nJob one was cleaning all of that up. Got page load time down to around 5-8 seconds without breaking any of the security constraints. It was my first big software project. The existing team had thrown their hands into the air for years trying to refactor the codebase and had given up long before i got there.', created_at=datetime.datetime(2025, 12, 22, 20, 44, 37, tzinfo=datetime.timezone.utc)), RedditComment(text='At work I completely reworked a script that stored a few plain CSV files in star scheme in a postgres DB. About 200.000 lines with 6 joined tables. The naive version using SQLModel (SQLAlchemy + Pydantic) took a few hours. Then I replaced everything in Polars and pre-calculated foreign keys. That version took 2 minutes but needed 5 GB ram. The newest Polars lazyframe version only requires 2 GB ram. The same custom Polars Io source with full Pydantic validation eats a CSV with 8 million lines for lunch.', created_at=datetime.datetime(2025, 12, 22, 20, 55, 13, tzinfo=datetime.timezone.utc)), RedditComment(text='Yeah man, the usual suspects I run into all the time when people send me their slow scripts:\\n\\n1.  Loops over big data – like for row in df.iterrows() or nested for-loops on lists with 10k+ items. Kills performance because Python loops are slow as hell compared to vectorized stuff.\\n\\n2.  Chaining a bunch of pandas operations without assigning – every filter or groupby makes a full copy if you’re not careful, and it adds up quick on bigger datasets.\\n\\n3.  Reading/writing files the wrong way – default pd.read_csv on huge files without chunksize, or writing row-by-row instead of in batches.\\n\\n4.  Too many copies of big objects – passing giant DataFrames around functions, or using .copy() everywhere when you don’t need to.\\n\\n5.  String concatenation in loops – doing result += something a million times still builds up quadratic time, even with f-strings.\\n\\n6.  Using .apply with a custom python function – basically just a disguised slow loop.\\n\\n7.  Loading way more data than you actually need – pulling in whole CSVs when you only care about a few columns.\\n\\n8.  Wrong tool for the job – using pandas for pure number crunching when NumPy would be faster, or lists when you should be using sets/dicts.\\nPretty much every slow script has 2-3 of these. Fixing the top couple usually gets you 10-30x, fixing more can push 80-100x+.\\nIf you’ve got something that’s dragging, feel free to paste a snippet or just describe what it’s doing and how long it takes  . I’ll tell you which of these are probably biting you. No charge or anything.', created_at=datetime.datetime(2025, 12, 22, 20, 37, 5, tzinfo=datetime.timezone.utc)), RedditComment(text=\"99.9% of the time it's using pandas data frame or numpy array like they are lists\", created_at=datetime.datetime(2025, 12, 22, 20, 56, 18, tzinfo=datetime.timezone.utc)), RedditComment(text=\"shooting from the hip here, but the usual suspects are:\\n\\n1. doing things sequentially which can be parallelized or done concurrently\\n\\n2. poorly coded retry logic, including excessively long timeouts\\n\\n3. non-optimal database interaction patterns, especially the case with large datasets, and especially extra the case with operations requiring locks that aren't handled gracefully\\n\\n4. doing repeated CPU intensive operations entirely in Python instead of using a library with bindings to an appropriate tool coded in lower level, more performant language. \\n\\n5. failing to use a cache where appropriate, resulting in repeated operations that didn't need to be repeated\", created_at=datetime.datetime(2025, 12, 22, 20, 41, 38, tzinfo=datetime.timezone.utc)), RedditComment(text='You give me code and I’ll just show you, otherwise you just hating for no reason', created_at=datetime.datetime(2025, 12, 22, 20, 41, 31, tzinfo=datetime.timezone.utc)), RedditComment(text='You right I agree.', created_at=datetime.datetime(2025, 12, 22, 20, 45, 1, tzinfo=datetime.timezone.utc))]),\n",
       " RedditPost(subreddit=Subreddit(display_name='Python'), created_at=datetime.datetime(2025, 12, 22, 19, 25, 25, tzinfo=datetime.timezone.utc), title='An easy way to break an email or url into its component parts: Pyrolysate', flair='Showcase', destination_url='https://www.reddit.com/r/Python/comments/1pt8h37/an_easy_way_to_break_an_email_or_url_into_its/', text=\"About a year ago, I had a simple question that I wanted to answer: Can I break emails and URLs into their component parts?\\n\\nThis project was meant to be an easy afternoon project, maybe a weekend project, that taught me a few things about email parsing, URL parsing, and python standard libraries. It was only after starting this project that I learnt all of the complexities specifically in different URL formats.\\n\\n# What My Project Does\\n\\nPyrolysate is a Python library and CLI tool for parsing and validating URLs and email addresses. It breaks down URLs and emails into their component parts, validates against IANA's official TLD list, and outputs structured data in JSON, CSV, or text format.\\n\\n* Support for using files as inputs\\n* CLI available\\n* Compressed file and zip archive parsing support\\n* Converts to JSON object and JSON file\\n* Converts to CSV object and CSV file\\n\\n# Target Audience\\n\\n* Anyone who needs to have structured output for their emails and/or URLs\\n\\n# Comparison\\n\\n* Similar to urllib.parse but with more features\\n\\n# Links\\n\\n* GitHub:\\xa0[https://github.com/lignum-vitae/pyrolysate](https://github.com/lignum-vitae/pyrolysate)\\n\\n# Feedback I’d love\\n\\n* Project layout\\n* Code style improvements\\n* CLI command design\", comments=[])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_posts(\"python\", limit=10)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3704ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = client.get_posts(\"python\", limit=30)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3c8db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda p: len(p.comments), ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df47dd6",
   "metadata": {},
   "source": [
    "# Fetch recent comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8698e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = client._reddit.subreddit(\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d790b5",
   "metadata": {},
   "source": [
    "# Test get_comments method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80e0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = client.get_comments(\"python\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31e178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e01d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditComment(text=\"From my understanding x\\\\*= -1 is wrong but when I remove it it'll give me negative prices. How can I fix that?\", created_at=datetime.datetime(2025, 12, 22, 21, 50, 31, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c67e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(sub.comments(limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f086dca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c2b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING_COMMENT_MESSAGE\n",
      "STR_FIELD\n",
      "all_awardings\n",
      "approved_at_utc\n",
      "approved_by\n",
      "archived\n",
      "associated_award\n",
      "author\n",
      "author_flair_background_color\n",
      "author_flair_css_class\n",
      "author_flair_richtext\n",
      "author_flair_template_id\n",
      "author_flair_text\n",
      "author_flair_text_color\n",
      "author_flair_type\n",
      "author_fullname\n",
      "author_is_blocked\n",
      "author_patreon_flair\n",
      "author_premium\n",
      "award\n",
      "awarders\n",
      "banned_at_utc\n",
      "banned_by\n",
      "block\n",
      "body\n",
      "body_html\n",
      "can_gild\n",
      "can_mod_post\n",
      "clear_vote\n",
      "collapse\n",
      "collapsed\n",
      "collapsed_because_crowd_control\n",
      "collapsed_reason\n",
      "collapsed_reason_code\n",
      "comment_type\n",
      "controversiality\n",
      "created\n",
      "created_utc\n",
      "delete\n",
      "disable_inbox_replies\n",
      "distinguished\n",
      "downs\n",
      "downvote\n",
      "edit\n",
      "edited\n",
      "enable_inbox_replies\n",
      "fullname\n",
      "gild\n",
      "gilded\n",
      "gildings\n",
      "id\n",
      "id_from_url\n",
      "is_root\n",
      "is_submitter\n",
      "likes\n",
      "link_author\n",
      "link_id\n",
      "link_permalink\n",
      "link_title\n",
      "link_url\n",
      "locked\n",
      "mark_read\n",
      "mark_unread\n",
      "mod\n",
      "mod_note\n",
      "mod_reason_by\n",
      "mod_reason_title\n",
      "mod_reports\n",
      "name\n",
      "no_follow\n",
      "num_comments\n",
      "num_reports\n",
      "over_18\n",
      "parent\n",
      "parent_id\n",
      "parse\n",
      "permalink\n",
      "quarantine\n",
      "refresh\n",
      "removal_reason\n",
      "replies\n",
      "reply\n",
      "report\n",
      "report_reasons\n",
      "save\n",
      "saved\n",
      "score\n",
      "score_hidden\n",
      "send_replies\n",
      "stickied\n",
      "submission\n",
      "subreddit\n",
      "subreddit_id\n",
      "subreddit_name_prefixed\n",
      "subreddit_type\n",
      "top_awarded_type\n",
      "total_awards_received\n",
      "treatment_tags\n",
      "unblock_subreddit\n",
      "uncollapse\n",
      "unrepliable_reason\n",
      "unsave\n",
      "ups\n",
      "upvote\n",
      "user_reports\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([attr for attr in dir(comments[0]) if not attr.startswith('_')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a778d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
